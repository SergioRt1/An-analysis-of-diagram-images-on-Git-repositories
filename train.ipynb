{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Building and running"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import hashlib\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.applications.densenet import preprocess_input\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from typing import Dict, Any"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set logging to only error"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and prepare dataset\n",
    "The dataset is composed by:\n",
    " * CSV with the labeling\n",
    " * Image folder with all the images normalized"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_folder = 'normalized_data_set_diagrams'\n",
    "labeled_csv = 'csv/diagram_images_dataset.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_map = {\n",
    "    1: 'Activity Diagram',\n",
    "    2: 'Sequence Diagram',\n",
    "    3: 'Class Diagram',\n",
    "    4: 'Component Diagram',\n",
    "    5: 'Use Case Diagram',\n",
    "    6: 'Cloud',\n",
    "    0: 'None',\n",
    "}\n",
    "input_shape_densenet = (224, 224, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "map_to_name = {}\n",
    "\n",
    "\n",
    "def load_dataset(dataset_folder_path, csv_path):\n",
    "    \"\"\"Loads a dataset of images\n",
    "        - dataset_folder_path is the path of the folder that contains the images\n",
    "        - csv_path is the path of the CSV file that contains the labels of the images\n",
    "        Returns: X_data, y_labeled\n",
    "        - X_data is a numpy.ndarray containing the pixel data of an image X\n",
    "        - y_labeled is a numpy.ndarray containing an int, the label Y for the image X in that index\n",
    "    \"\"\"\n",
    "    X_data = []\n",
    "\n",
    "    data = pd.read_csv(csv_path, dtype={\"Name\": str, \"Category\": np.uint8})\n",
    "\n",
    "    for image_name in data.Name:\n",
    "        img = keras.utils.load_img(f'{dataset_folder_path}/{image_name}', target_size=input_shape_densenet[:2])\n",
    "        img = keras.utils.img_to_array(img)\n",
    "        hash_value = hashlib.sha1(img).hexdigest()[:15]\n",
    "        map_to_name[hash_value] = image_name\n",
    "        X_data.append(img)\n",
    "\n",
    "    X_data = np.array(X_data)\n",
    "    y_labeled = np.array(data.Category)\n",
    "\n",
    "    print(\"Data loaded\\n\", data)\n",
    "    return X_data, y_labeled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_data(x, y, m):\n",
    "    \"\"\"Pre-processes the data for the model\n",
    "        - x is a numpy.ndarray of shape (m, 224, 224, 3) containing\n",
    "         a list of image pixels, where m is the number of images\n",
    "        - y is a numpy.ndarray of shape (m,) containing\n",
    "         the labels for x\n",
    "        - m is the number of categories in the classifier\n",
    "        Returns: X_p, Y_p\n",
    "        - X_p is a numpy.ndarray containing the preprocessed X\n",
    "        - Y_p is a numpy.ndarray containing the preprocessed Y\n",
    "    \"\"\"\n",
    "    x_p = preprocess_input(np.copy(x))\n",
    "    y_p = keras.utils.to_categorical(y, m)\n",
    "\n",
    "    return x_p, y_p"
   ],
   "metadata": {
    "id": "w3K893oYu-Yo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remap_names_preprocessed(x_full, x_full_preprocessed):\n",
    "    map_names = {}\n",
    "    for i in range(len(x_full)):\n",
    "        hash_original = hashlib.sha1(x_full[i]).hexdigest()[:15]\n",
    "        hash_preprocessed = hashlib.sha1(x_full_preprocessed[i]).hexdigest()[:15]\n",
    "        map_names[hash_preprocessed] = map_to_name[hash_original]\n",
    "\n",
    "    return map_names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "x_full, y_full = load_dataset(dataset_folder, labeled_csv)\n",
    "x_full_p, y_full_p = preprocess_data(x_full, y_full, 7)\n",
    "\n",
    "preprocessed_to_name = remap_names_preprocessed(x_full, x_full_p)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5-LOFYMvMor",
    "outputId": "4fb00371-21b1-4122-932e-e8988fb21fea",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building DenseNet169"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_network(trainable: bool, retrain_last: bool):\n",
    "    \"\"\"Pre-processes the data for the model\n",
    "        - trainable boolean to indicate if the network would be fully trainable\n",
    "        - retrain_last boolean to indicate if the last layer would be trainable\n",
    "        Returns: densenet_model\n",
    "        - densenet_model is a Keras DenseNet169 model\n",
    "    \"\"\"\n",
    "    densenet_model = keras.applications.DenseNet169(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=None,\n",
    "        input_shape=input_shape_densenet,\n",
    "        pooling=None\n",
    "    )\n",
    "\n",
    "    densenet_model.trainable = True\n",
    "\n",
    "    if not trainable:\n",
    "        for layer in densenet_model.layers:\n",
    "            if retrain_last and 'conv5' in layer.name:\n",
    "                layer.trainable = True\n",
    "            else:\n",
    "                layer.trainable = False\n",
    "\n",
    "    return densenet_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add new layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_extra_layers(densenet_model, layer_size: int, dropout: bool, number_of_layers: int):\n",
    "    \"\"\"Add extra layers to a Keras model for transfer learning.\n",
    "        - densenet_model is a pre-trained Keras model with input (224, 224, 3)\n",
    "        - layer_size is an int, the size of the first Dense layer\n",
    "        - dropout is a bool, indicating if a Dropout layer will be added\n",
    "          between Dense layers\n",
    "        Returns: model\n",
    "        - model a Keras model with the layer added\n",
    "    \"\"\"\n",
    "    initializer = keras.initializers.he_normal(seed=32)\n",
    "    inputs = keras.Input(shape=input_shape_densenet)\n",
    "\n",
    "    layer = densenet_model(inputs)\n",
    "    layer = keras.layers.Flatten()(layer)\n",
    "\n",
    "    layer = keras.layers.BatchNormalization()(layer)\n",
    "\n",
    "    for n in range(1, number_of_layers + 1):\n",
    "        layer = keras.layers.Dense(units=layer_size / n,\n",
    "                                   activation='relu',\n",
    "                                   kernel_initializer=initializer\n",
    "                                   )(layer)\n",
    "        if dropout:\n",
    "            layer = keras.layers.Dropout(0.5)(layer)\n",
    "\n",
    "        layer = keras.layers.BatchNormalization()(layer)\n",
    "\n",
    "    layer = keras.layers.Dense(units=7,\n",
    "                               activation='softmax',\n",
    "                               kernel_initializer=initializer\n",
    "                               )(layer)\n",
    "\n",
    "    model = keras.models.Model(inputs, outputs=layer)\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validate results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_network_with_params(params: Dict[str, Any]):\n",
    "    network = build_network(params['fully_trainable'], params['retrain_last'])\n",
    "    network = add_extra_layers(network, params['first_layer_size'], params['dropout'], params['number_of_layers'])\n",
    "    network.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=keras.optimizers.Adam(),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    return network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_with_k_fold_cross_validation(n_folds: int, params: Dict[str, Any]):\n",
    "    \"\"\"Create and train a DenseNet model n_folds times with a different training/validation partition data.\n",
    "        - n_folds the number of times the model will be trained\n",
    "        - params map string -> value with the configuration of the network, the possible values are:\n",
    "            - first_layer_size is an int, the size of the first Dense layer\n",
    "            - fully_trainable boolean to indicate if the network would be fully trainable\n",
    "            - retrain_last boolean to indicate if the last layer would be trainable\n",
    "            - dropout is a bool, indicating if a Dropout layer will be added\n",
    "              between Dense layers\n",
    "            - number_of_layers is the number of extra layers Dense appended to the network\n",
    "        Returns: histories\n",
    "        - histories a list of size n_folds with the detailed training history of each attempt\n",
    "    \"\"\"\n",
    "    histories = []\n",
    "    for fold in range(n_folds):\n",
    "        network = build_network_with_params(params)\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(x_full_p, y_full_p, test_size=0.2, random_state=fold * 5)\n",
    "        history = network.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), verbose=2)\n",
    "        del network\n",
    "        histories.append(history)\n",
    "\n",
    "    return histories"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_with_simple_holdout_validation(X_train, X_val, y_train, y_val, params: Dict[str, Any]):\n",
    "    \"\"\"Create and train a DenseNet model with the given data.\n",
    "        - params map string -> value with the configuration of the network, the possible values are:\n",
    "            - first_layer_size is an int, the size of the first Dense layer\n",
    "            - fully_trainable boolean to indicate if the network would be fully trainable\n",
    "            - retrain_last boolean to indicate if the last layer would be trainable\n",
    "            - dropout is a bool, indicating if a Dropout layer will be added\n",
    "              between Dense layers\n",
    "            - number_of_layers is the number of extra layers Dense appended to the network\n",
    "        Returns: model\n",
    "        - model a Keras model of th modified DenseNet169\n",
    "    \"\"\"\n",
    "    network = build_network_with_params(params)\n",
    "\n",
    "    history = network.fit(X_train, y_train, epochs=2, validation_data=(X_val, y_val), verbose=2)\n",
    "\n",
    "    network.save('diagrams.h5')\n",
    "    return network, history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Refinement"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Helper functions to plot the results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_history_mean(k_history, prop: str):\n",
    "    mean_prop = [h.history[prop] for h in k_history]\n",
    "    mean = np.mean(mean_prop, axis=0)\n",
    "    return mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_model_accuracy(accs, losses, legends):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for acc_value in accs:\n",
    "        plt.plot(acc_value)\n",
    "        l = len(acc_value) - 1\n",
    "        plt.text(l, acc_value[l], \"{:.1f}%\".format(acc_value[l] * 100))\n",
    "    plt.legend(legends, loc='lower right')\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for loss_value in losses:\n",
    "        plt.plot(loss_value)\n",
    "        l = len(loss_value) - 1\n",
    "        plt.text(l, loss_value[l], \"{:.1f}%\".format(loss_value[l] * 100))\n",
    "    plt.legend(legends, loc='upper right')\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.savefig('number_of_layers.png')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_model_comparison(history, legends):\n",
    "    val_acc = map(get_history_mean, history, ['val_accuracy'] * len(history))\n",
    "    val_loss = map(get_history_mean, history, ['val_loss'] * len(history))\n",
    "\n",
    "    plot_model_accuracy(val_acc, val_loss, legends)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Number of extra layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extra_layers_test():\n",
    "    history = []\n",
    "    base_params = {\n",
    "        'first_layer_size': 128,\n",
    "        'fully_trainable': False,\n",
    "        'retrain_last': True,\n",
    "        'dropout': True,\n",
    "    }\n",
    "    n_layers = [0, 1, 2]\n",
    "\n",
    "    for n_layer in n_layers:\n",
    "        params = base_params.update(number_of_layers=n_layer)\n",
    "        h = np.array(train_with_k_fold_cross_validation(folds, params))\n",
    "        history.append(h)\n",
    "    plot_model_comparison(history, n_layers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extra_layers_test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Size of the first layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def first_layer_size_test():\n",
    "    history = []\n",
    "    base_params = {\n",
    "        'fully_trainable': False,\n",
    "        'retrain_last': True,\n",
    "        'dropout': True,\n",
    "        'number_of_layers': 1,\n",
    "    }\n",
    "    first_layer_size = [512, 256, 128, 64]\n",
    "\n",
    "    for layer_size in first_layer_size:\n",
    "        params = base_params.update(first_layer_size=layer_size)\n",
    "        h = np.array(train_with_k_fold_cross_validation(folds, params))\n",
    "        history.append(h)\n",
    "    plot_model_comparison(history, first_layer_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "first_layer_size_test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dropout"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dropout_test():\n",
    "    history = []\n",
    "    base_params = {\n",
    "        'first_layer_size': 128,\n",
    "        'fully_trainable': False,\n",
    "        'retrain_last': True,\n",
    "        'number_of_layers': 1,\n",
    "    }\n",
    "    dropout = [True, False]\n",
    "\n",
    "    for option in dropout:\n",
    "        params = base_params.update(dropout=option)\n",
    "        h = np.array(train_with_k_fold_cross_validation(folds, params))\n",
    "        history.append(h)\n",
    "    plot_model_comparison(history, ['Dropout', 'Without'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dropout_test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Retrain last layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def retrain_last_layer_test():\n",
    "    history = []\n",
    "    base_params = {\n",
    "        'first_layer_size': 128,\n",
    "        'fully_trainable': False,\n",
    "        'dropout': True,\n",
    "        'number_of_layers': 1,\n",
    "    }\n",
    "    retrain_last = [True, False]\n",
    "\n",
    "    for option in retrain_last:\n",
    "        params = base_params.update(retrain_last=option)\n",
    "        h = np.array(train_with_k_fold_cross_validation(folds, params))\n",
    "        history.append(h)\n",
    "    plot_model_comparison(history, ['Retrained', 'Frozen'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "retrain_last_layer_test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validating failed cases and measure model performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def validate_failed(model, X, y, X_original, show_image: bool):\n",
    "    prob = model.predict(X, verbose=1)\n",
    "    predictions = prob.argmax(axis=-1)\n",
    "    expected_y = y.argmax(axis=-1)\n",
    "    fails = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] != expected_y[i]:\n",
    "            fails += 1\n",
    "            if show_image:\n",
    "                hash_value = hashlib.sha1(X_original[i]).hexdigest()[:15]\n",
    "                name = map_to_name[hash_value]\n",
    "                print(\n",
    "                    f'\\r{name} Expected {expected_y[i]} ({prob[i][expected_y[i]]}) but got {predictions[i]} ({prob[i][predictions[i]]})',\n",
    "                    flush=True, end=' ' * 50)\n",
    "                cv2.imshow('Failed', X[i])\n",
    "                cv2.imshow('Original', X_original[i])\n",
    "                cv2.waitKey(0)\n",
    "    print(f'Failed: {fails}')\n",
    "\n",
    "    return classification_report(expected_y, predictions, digits=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Final transfer learning model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def validate_failed(model, X, y, show_image: bool):\n",
    "    print('\\nValidation process:')\n",
    "    prob = model.predict(X, verbose=1)\n",
    "    predictions = prob.argmax(axis=-1)\n",
    "    expected_y = y.argmax(axis=-1)\n",
    "    fails = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] != expected_y[i]:\n",
    "            fails += 1\n",
    "            if show_image:\n",
    "                hash_value = hashlib.sha1(X[i]).hexdigest()[:15]\n",
    "                name = preprocessed_to_name[hash_value]\n",
    "                original = cv2.imread(f'{dataset_folder}/{name}', cv2.IMREAD_ANYCOLOR)\n",
    "                print(f'\\r{name} Expected {expected_y[i]} ({prob[i][expected_y[i]]}) but got {predictions[i]} ({prob[i][predictions[i]]})',\n",
    "                    flush=True, end=' ' * 50)\n",
    "\n",
    "                cv2.imshow('Preprocessed', X[i])\n",
    "                cv2.imshow('Original', original)\n",
    "                cv2.waitKey(0)\n",
    "    print(f'Failed: {fails}')\n",
    "\n",
    "    return classification_report(expected_y, predictions, digits=4)\n",
    "\n",
    "\n",
    "def generate_final_model(seed: int, show_image: bool):\n",
    "    final_params = {\n",
    "        'first_layer_size': 128,\n",
    "        'fully_trainable': False,\n",
    "        'retrain_last': True,\n",
    "        'dropout': True,\n",
    "        'number_of_layers': 1,\n",
    "    }\n",
    "    X_train, X_val, y_train, y_val = train_test_split(x_full_p, y_full_p, test_size=0.2, random_state=seed)\n",
    "\n",
    "    model, history = train_with_simple_holdout_validation(X_train, X_val, y_train, y_val, final_params)\n",
    "    report = validate_failed(model, X_val, y_val, show_image)\n",
    "    print('\\nClassification report:')\n",
    "    print(report)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "\n",
    "transfer_learning_model, transfer_learning_history = generate_final_model(random.randint(1, 1000), True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transfer_learning_model, transfer_learning_history = generate_final_model(random.randint(1, 1000), True)\n",
    "# transfer_learning_model = keras.models.load_model('diagrams.h5')\n",
    "\n",
    "plot_model_comparison([transfer_learning_history], ['Transfer learning'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-tuning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fine_tuning(model, seed):\n",
    "    model.trainable = True\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.Adam(1e-5),\n",
    "                  metrics=['accuracy'])\n",
    "    X_train, X_val, y_train, y_val = train_test_split(x_full_p, y_full_p, test_size=0.2, random_state=seed)\n",
    "    model.summary()\n",
    "    history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "    return model, history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fine_tuned_model, fine_tuned_history = fine_tuning(transfer_learning_model, random.randint(1, 1000))\n",
    "plot_model_comparison([fine_tuned_history, transfer_learning_history], ['Fine-tuning', 'Without'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fine_tuned_model.save('tuned.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing new cases"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model('diagrams.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_and_predict_img(name: str, model):\n",
    "    original = cv2.imread('test/' + name, cv2.IMREAD_ANYCOLOR)\n",
    "    original = cv2.cvtColor(original, cv2.COLOR_RGB2BGR)\n",
    "    img = keras.utils.load_img(f'test/{name}', target_size=input_shape_densenet[:2])\n",
    "    img = keras.utils.img_to_array(img)\n",
    "    x = np.expand_dims(img, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(original)\n",
    "    title = plt.title(f'Original {name}')\n",
    "    plt.setp(title, color='r')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x[0])\n",
    "    title = plt.title(f'Preprocessed {name}')\n",
    "    plt.setp(title, color='r')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    prop = model.predict(x)\n",
    "    prediction = prop.argmax(axis=-1)\n",
    "    print(f\"Prediction: {prediction[0]} -> {class_map[prediction[0]]}\")\n",
    "\n",
    "    return prop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_and_predict_img('pollo.jpg', loaded_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}