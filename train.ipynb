{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Building and running"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import hashlib\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and prepare dataset\n",
    "The dataset is composed by:\n",
    " * CSV with the labeling\n",
    " * Image folder with all the images normalized"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataset_folder = 'normalized_data_set_diagrams/'\n",
    "labeled_csv = 'csv/diagram_images_dataset.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "map_to_name = {}\n",
    "\n",
    "\n",
    "def load_dataset(dataset_folder_path, csv_path):\n",
    "    \"\"\"Loads a dataset of images\n",
    "        - dataset_folder_path is the path of the folder that contains the images\n",
    "        - csv_path is the path of the CSV file that contains the labels of the images\n",
    "        Returns: X_data, y_labeled\n",
    "        - X_data is a numpy.ndarray containing the pixel data of an image X\n",
    "        - y_labeled is a numpy.ndarray containing an int, the label Y for the image X in that index\n",
    "    \"\"\"\n",
    "    X_data = []\n",
    "\n",
    "    data = pd.read_csv(csv_path, dtype={\"Name\": str, \"Category\": np.uint8})\n",
    "\n",
    "    for image_name in data.Name:\n",
    "        img = cv2.imread(dataset_folder_path + image_name, cv2.IMREAD_COLOR)\n",
    "        hash = hashlib.sha1(img).hexdigest()[:15]\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        map_to_name[hash] = image_name\n",
    "        X_data.append(img)\n",
    "\n",
    "    X_data = np.array(X_data)\n",
    "    y_labeled = np.array(data.Category)\n",
    "\n",
    "    print(\"Data loaded\\n\", data)\n",
    "    return X_data, y_labeled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_data(x, y, m):\n",
    "    \"\"\"Pre-processes the data for the model\n",
    "        - x is a numpy.ndarray of shape (m, 224, 224, 3) containing\n",
    "         a list of image pixels, where m is the number of images\n",
    "        - y is a numpy.ndarray of shape (m,) containing\n",
    "         the labels for x\n",
    "        - m is the number of categories in the classifier\n",
    "        Returns: X_p, Y_p\n",
    "        - X_p is a numpy.ndarray containing the preprocessed X\n",
    "        - Y_p is a numpy.ndarray containing the preprocessed Y\n",
    "    \"\"\"\n",
    "    X_p = keras.applications.densenet.preprocess_input(x)\n",
    "\n",
    "    y_p = keras.utils.to_categorical(y, m)\n",
    "\n",
    "    return X_p, y_p"
   ],
   "metadata": {
    "id": "w3K893oYu-Yo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_full, y_full = load_dataset(dataset_folder, labeled_csv)\n",
    "X_full_p, y_full_p = preprocess_data(X_full, y_full, 7)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5-LOFYMvMor",
    "outputId": "4fb00371-21b1-4122-932e-e8988fb21fea",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n",
      "                      Name  Category\n",
      "0     7a668879d103ba8.jpg         1\n",
      "1     4bab7d342c24e3f.jpg         1\n",
      "2     d6c5e6d46cbbb26.jpg         1\n",
      "3     e215c30192cc297.jpg         1\n",
      "4     0fd2b9ef096d9cb.jpg         1\n",
      "...                   ...       ...\n",
      "5551  d2254621efd8d52.jpg         0\n",
      "5552  de2268621d5e911.jpg         0\n",
      "5553  90fe34f3f8107ee.jpg         0\n",
      "5554  f065035fafcf430.jpg         0\n",
      "5555  30efd0c8a1649e1.jpg         0\n",
      "\n",
      "[5556 rows x 2 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building DenseNet169"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "input_shape_densenet = (224, 224, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def build_network(trainable: bool, retrain_last: bool):\n",
    "    \"\"\"Pre-processes the data for the model\n",
    "        - trainable boolean to indicate if the network would be fully trainable\n",
    "        - retrain_last boolean to indicate if the last layer would be trainable\n",
    "        Returns: densenet_model\n",
    "        - densenet_model is a Keras DenseNet169 model\n",
    "    \"\"\"\n",
    "    densenet_model = keras.applications.DenseNet169(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=None,\n",
    "        input_shape=input_shape_densenet,\n",
    "        pooling=None\n",
    "    )\n",
    "\n",
    "    densenet_model.trainable = True\n",
    "\n",
    "    if not trainable:\n",
    "        for layer in densenet_model.layers:\n",
    "            if retrain_last and 'conv5' in layer.name:\n",
    "                layer.trainable = True\n",
    "            else:\n",
    "                layer.trainable = False\n",
    "\n",
    "    return densenet_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add new layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def add_extra_layers(densenet_model, layer_size: int, dropout: bool, number_of_layers: int):\n",
    "    \"\"\"Add extra layers to a Keras model for transfer learning.\n",
    "        - densenet_model is a pre-trained Keras model with input (224, 224, 3)\n",
    "        - layer_size is an int, the size of the first Dense layer\n",
    "        - dropout is a bool, indicating if a Dropout layer will be added\n",
    "          between Dense layers\n",
    "        Returns: model\n",
    "        - model a Keras model with the layer added\n",
    "    \"\"\"\n",
    "    initializer = keras.initializers.he_normal(seed=32)\n",
    "    inputs = keras.Input(shape=input_shape_densenet)\n",
    "\n",
    "    layer = densenet_model(inputs)\n",
    "    layer = keras.layers.Flatten()(layer)\n",
    "\n",
    "    layer = keras.layers.BatchNormalization()(layer)\n",
    "\n",
    "    for n in range(1, number_of_layers + 1):\n",
    "        layer = keras.layers.Dense(units=layer_size / n,\n",
    "                                   activation='relu',\n",
    "                                   kernel_initializer=initializer\n",
    "                                   )(layer)\n",
    "        if dropout:\n",
    "            layer = keras.layers.Dropout(0.5)(layer)\n",
    "\n",
    "        layer = keras.layers.BatchNormalization()(layer)\n",
    "\n",
    "    layer = keras.layers.Dense(units=7,\n",
    "                               activation='softmax',\n",
    "                               kernel_initializer=initializer\n",
    "                               )(layer)\n",
    "\n",
    "    model = keras.models.Model(inputs, outputs=layer)\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validate results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def train_with_k_fold_cross_validation(n_folds: int, layer_size: int, trainable: bool, retrain_last: bool,\n",
    "                                       dropout: bool, number_of_layers: int):\n",
    "    \"\"\"Create and train a DenseNet model n_folds times with a different training/validation partition data.\n",
    "        - n_folds the number of times the model will be trained\n",
    "        - layer_size is an int, the size of the first Dense layer\n",
    "        - trainable boolean to indicate if the network would be fully trainable\n",
    "        - retrain_last boolean to indicate if the last layer would be trainable\n",
    "        - dropout is a bool, indicating if a Dropout layer will be added\n",
    "          between Dense layers\n",
    "        Returns: histories\n",
    "        - histories a list of size n_folds with the detailed training history of each attempt\n",
    "    \"\"\"\n",
    "    histories = []\n",
    "    for fold in range(n_folds):\n",
    "        network = build_network(trainable, retrain_last)\n",
    "        network = add_extra_layers(network, layer_size, dropout, number_of_layers)\n",
    "        network.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=keras.optimizers.Adam(),\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_full_p, y_full_p, test_size=0.2, random_state=fold * 5)\n",
    "        history = network.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), verbose=2)\n",
    "        del network\n",
    "        histories.append(history)\n",
    "\n",
    "    return histories"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train_with_simple_holdout_validation(X_train, X_val, y_train, y_val):\n",
    "    network = build_network(True)\n",
    "    network = add_extra_layers(network, 128, True, 1)\n",
    "    network.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=keras.optimizers.Adam(),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    network.fit(X_train, y_train, epochs=9, validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "    network.save('diagrams.h5')\n",
    "    return network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Refinement"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Helper functions to plot the results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_history_mean(k_history, prop: str):\n",
    "    mean_prop = [h.history[prop] for h in k_history]\n",
    "    mean = np.mean(mean_prop, axis=0)\n",
    "    return mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def plot_model_accuracy(accs, losses, legends):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for acc_value in accs:\n",
    "        plt.plot(acc_value)\n",
    "        l = len(acc_value) - 1\n",
    "        plt.text(l, acc_value[l], \"{:.1f}%\".format(acc_value[l] * 100))\n",
    "    plt.legend(legends, loc='lower right')\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for loss_value in losses:\n",
    "        plt.plot(loss_value)\n",
    "        l = len(loss_value) - 1\n",
    "        plt.text(l, loss_value[l], \"{:.1f}%\".format(loss_value[l] * 100))\n",
    "    plt.legend(legends, loc='upper right')\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.savefig('number_of_layers.png')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_model_comparison(history, legends):\n",
    "    val_acc = map(get_history_mean, history, ['val_accuracy'] * len(history))\n",
    "    val_loss = map(get_history_mean, history, ['val_loss'] * len(history))\n",
    "\n",
    "    plot_model_accuracy(val_acc, val_loss, legends)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Number of extra layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extra_layers_test():\n",
    "    history = []\n",
    "    first_layer_size = 128\n",
    "    fully_trainable = False\n",
    "    retrain_last = True\n",
    "    dropout = True\n",
    "    n_layers = [0, 1, 2]\n",
    "    for n_layer in n_layers:\n",
    "        h = np.array(train_with_k_fold_cross_validation(folds, first_layer_size, fully_trainable, retrain_last, dropout, n_layer))\n",
    "        history.append(h)\n",
    "    plot_model_comparison(history, n_layers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extra_layers_test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Size of the first layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def first_layer_size_test():\n",
    "    history = []\n",
    "    first_layer_size = [512, 256, 128, 64]\n",
    "    fully_trainable = False\n",
    "    retrain_last = True\n",
    "    dropout = True\n",
    "    n_layers = 1\n",
    "    for layer_size in first_layer_size:\n",
    "        h = np.array(train_with_k_fold_cross_validation(folds, layer_size, fully_trainable, retrain_last, dropout, n_layers))\n",
    "        history.append(h)\n",
    "    plot_model_comparison(history, first_layer_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "first_layer_size_test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Dropout"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dropout_test():\n",
    "    history = []\n",
    "    first_layer_size = 128\n",
    "    fully_trainable = False\n",
    "    retrain_last = True\n",
    "    dropout = [True, False]\n",
    "    n_layers = 1\n",
    "    for option in dropout:\n",
    "        h = np.array(train_with_k_fold_cross_validation(folds, first_layer_size, fully_trainable, retrain_last, option, n_layers))\n",
    "        history.append(h)\n",
    "    plot_model_comparison(history, ['Dropout', 'Without'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dropout_test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Retrain last layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def retrain_last_layer_test():\n",
    "    history = []\n",
    "    first_layer_size = 128\n",
    "    fully_trainable = False\n",
    "    retrain_last = [True, False]\n",
    "    dropout = True\n",
    "    n_layers = 1\n",
    "    for option in retrain_last:\n",
    "        h = np.array(train_with_k_fold_cross_validation(folds, first_layer_size, fully_trainable, option, dropout, n_layers))\n",
    "        history.append(h)\n",
    "    plot_model_comparison(history, ['Retrained', 'Frozen'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "retrain_last_layer_test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fine-tuning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_final_model(seed):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_full_p, y_full_p, test_size=0.2, random_state=seed)\n",
    "    _, X_original, _, _ = train_test_split(X_full, y_full, test_size=0.2, random_state=seed)\n",
    "\n",
    "    model = train_with_simple_holdout_validation(X_train, X_val, y_train, y_val)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " densenet169 (Functional)    (None, 7, 7, 1664)        12642880  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 81536)             0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 81536)            326144    \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               10436736  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,407,175\n",
      "Trainable params: 23,085,447\n",
      "Non-trainable params: 321,728\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-01 01:28:33.298427: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.9653"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-01 01:30:50.807744: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 165s 1s/step - loss: 0.1081 - accuracy: 0.9653 - val_loss: 0.0196 - val_accuracy: 0.9946\n",
      "Epoch 2/10\n",
      "139/139 [==============================] - 133s 946ms/step - loss: 0.0407 - accuracy: 0.9863 - val_loss: 0.0185 - val_accuracy: 0.9910\n",
      "Epoch 3/10\n",
      "139/139 [==============================] - 133s 951ms/step - loss: 0.0303 - accuracy: 0.9901 - val_loss: 0.0153 - val_accuracy: 0.9928\n",
      "Epoch 4/10\n",
      "139/139 [==============================] - 134s 960ms/step - loss: 0.0243 - accuracy: 0.9935 - val_loss: 0.0157 - val_accuracy: 0.9928\n",
      "Epoch 5/10\n",
      "139/139 [==============================] - 133s 955ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.0148 - val_accuracy: 0.9937\n",
      "Epoch 6/10\n",
      "139/139 [==============================] - 133s 954ms/step - loss: 0.0108 - accuracy: 0.9980 - val_loss: 0.0148 - val_accuracy: 0.9937\n",
      "Epoch 7/10\n",
      "139/139 [==============================] - 134s 960ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.0138 - val_accuracy: 0.9937\n",
      "Epoch 8/10\n",
      "139/139 [==============================] - 132s 946ms/step - loss: 0.0109 - accuracy: 0.9980 - val_loss: 0.0136 - val_accuracy: 0.9946\n",
      "Epoch 9/10\n",
      "139/139 [==============================] - 133s 948ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0120 - val_accuracy: 0.9946\n",
      "Epoch 10/10\n",
      "139/139 [==============================] - 133s 955ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.0108 - val_accuracy: 0.9973\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x6e53d8fd0>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = keras.models.load_model('diagrams.h5')\n",
    "loaded_model.trainable = True\n",
    "loaded_model.compile(loss='categorical_crossentropy',\n",
    "                     optimizer=keras.optimizers.Adam(1e-5),\n",
    "                     metrics=['accuracy'])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_full_p, y_full_p, test_size=0.2, random_state=20)\n",
    "loaded_model.summary()\n",
    "history = loaded_model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), verbose=1)\n",
    "history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Validating failed cases and measure model performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def validate_failed(model, X, y, X_original, show_image: bool):\n",
    "    prob = model.predict(X, verbose=1)\n",
    "    predictions = prob.argmax(axis=-1)\n",
    "    expected_y = y.argmax(axis=-1)\n",
    "    fails = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] != expected_y[i]:\n",
    "            fails += 1\n",
    "            if show_image:\n",
    "                hash = hashlib.sha1(X_original[i]).hexdigest()[:15]\n",
    "                name = map_to_name[hash]\n",
    "                print(\n",
    "                    f'\\r{name} Expected {expected_y[i]} ({prob[i][expected_y[i]]}) but got {predictions[i]} ({prob[i][predictions[i]]})',\n",
    "                    flush=True, end=' ' * 50)\n",
    "                cv2.imshow('Failed', X_val[i])\n",
    "                cv2.imshow('Original', X_original[i])\n",
    "                cv2.waitKey(0)\n",
    "    print(f'Failed: {fails}')\n",
    "\n",
    "    return classification_report(expected_y, predictions, digits=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-01 01:52:22.184183: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 17s 399ms/step\n",
      "Failed: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       205\n",
      "           1     1.0000    1.0000    1.0000       115\n",
      "           2     1.0000    1.0000    1.0000       160\n",
      "           3     1.0000    1.0000    1.0000       208\n",
      "           4     1.0000    1.0000    1.0000        68\n",
      "           5     1.0000    1.0000    1.0000       169\n",
      "           6     1.0000    1.0000    1.0000       187\n",
      "\n",
      "    accuracy                         1.0000      1112\n",
      "   macro avg     1.0000    1.0000    1.0000      1112\n",
      "weighted avg     1.0000    1.0000    1.0000      1112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "failed = validate_failed(loaded_model, X_val, y_val, X_original, False)\n",
    "print(failed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing new cases"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model('diagrams.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def show_and_predict_img(name: str, model):\n",
    "    img = cv2.imread('test/' + name, cv2.IMREAD_ANYCOLOR)\n",
    "    im = np.array([img])\n",
    "    im = keras.applications.densenet.preprocess_input(im)\n",
    "\n",
    "    cv2.imshow('img', img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    prop = model.predict(im)\n",
    "    prediction = prop.argmax(axis=-1)\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "\n",
    "    return prop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "loaded_model.save('tuned.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[9.87176120e-01, 4.80586867e-04, 2.15088457e-05, 1.15415314e-02,\n        5.98010025e-04, 7.62242125e-05, 1.05956795e-04]], dtype=float32)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_and_predict_img('e78f463f0008003.jpg', loaded_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}