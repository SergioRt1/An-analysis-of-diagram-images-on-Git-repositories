{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Building and running"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import hashlib\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.applications.densenet import preprocess_input\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from typing import Dict, Any"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set logging to only error"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and prepare dataset\n",
    "The dataset is composed by:\n",
    " * CSV with the labeling\n",
    " * Image folder with all the images normalized"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "dataset_folder = 'normalized_data_set_diagrams'\n",
    "labeled_csv = 'csv/diagram_images_dataset.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "class_map = {\n",
    "    1: 'Activity Diagram',\n",
    "    2: 'Sequence Diagram',\n",
    "    3: 'Class Diagram',\n",
    "    4: 'Component Diagram',\n",
    "    5: 'Use Case Diagram',\n",
    "    6: 'Cloud',\n",
    "    0: 'None',\n",
    "}\n",
    "input_shape_densenet = (224, 224, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "map_to_name = {}\n",
    "\n",
    "\n",
    "def load_dataset(dataset_folder_path, csv_path):\n",
    "    \"\"\"Loads a dataset of images\n",
    "        - dataset_folder_path is the path of the folder that contains the images\n",
    "        - csv_path is the path of the CSV file that contains the labels of the images\n",
    "        Returns: X_data, y_labeled\n",
    "        - X_data is a numpy.ndarray containing the pixel data of an image X\n",
    "        - y_labeled is a numpy.ndarray containing an int, the label Y for the image X in that index\n",
    "    \"\"\"\n",
    "    X_data = []\n",
    "\n",
    "    data = pd.read_csv(csv_path, dtype={\"Name\": str, \"Category\": np.uint8})\n",
    "\n",
    "    for image_name in data.Name:\n",
    "        img = keras.utils.load_img(f'{dataset_folder_path}/{image_name}', target_size=input_shape_densenet[:2], interpolation=\"lanczos\")\n",
    "        img = keras.utils.img_to_array(img)\n",
    "        hash_value = hashlib.sha1(img).hexdigest()[:15]\n",
    "        map_to_name[hash_value] = image_name\n",
    "        X_data.append(img)\n",
    "\n",
    "    X_data = np.array(X_data)\n",
    "    y_labeled = np.array(data.Category)\n",
    "\n",
    "    print(\"Data loaded\\n\", data)\n",
    "    return X_data, y_labeled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_data(x, y, m):\n",
    "    \"\"\"Pre-processes the data for the model\n",
    "        - x is a numpy.ndarray of shape (m, 224, 224, 3) containing\n",
    "         a list of image pixels, where m is the number of images\n",
    "        - y is a numpy.ndarray of shape (m,) containing\n",
    "         the labels for x\n",
    "        - m is the number of categories in the classifier\n",
    "        Returns: X_p, Y_p\n",
    "        - X_p is a numpy.ndarray containing the preprocessed X\n",
    "        - Y_p is a numpy.ndarray containing the preprocessed Y\n",
    "    \"\"\"\n",
    "    x_p = preprocess_input(np.copy(x))\n",
    "    y_p = keras.utils.to_categorical(y, m)\n",
    "\n",
    "    return x_p, y_p"
   ],
   "metadata": {
    "id": "w3K893oYu-Yo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def remap_names_preprocessed(x_full, x_full_preprocessed):\n",
    "    map_names = {}\n",
    "    for i in range(len(x_full)):\n",
    "        hash_original = hashlib.sha1(x_full[i]).hexdigest()[:15]\n",
    "        hash_preprocessed = hashlib.sha1(x_full_preprocessed[i]).hexdigest()[:15]\n",
    "        map_names[hash_preprocessed] = map_to_name[hash_original]\n",
    "\n",
    "    return map_names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "x_full, y_full = load_dataset(dataset_folder, labeled_csv)\n",
    "x_full_p, y_full_p = preprocess_data(x_full, y_full, 7)\n",
    "\n",
    "preprocessed_to_name = remap_names_preprocessed(x_full, x_full_p)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5-LOFYMvMor",
    "outputId": "4fb00371-21b1-4122-932e-e8988fb21fea",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n",
      "                      Name  Category\n",
      "0     7a668879d103ba8.jpg         1\n",
      "1     4bab7d342c24e3f.jpg         1\n",
      "2     d6c5e6d46cbbb26.jpg         1\n",
      "3     e215c30192cc297.jpg         1\n",
      "4     0fd2b9ef096d9cb.jpg         1\n",
      "...                   ...       ...\n",
      "5551  d2254621efd8d52.jpg         0\n",
      "5552  de2268621d5e911.jpg         0\n",
      "5553  90fe34f3f8107ee.jpg         0\n",
      "5554  f065035fafcf430.jpg         0\n",
      "5555  30efd0c8a1649e1.jpg         0\n",
      "\n",
      "[5556 rows x 2 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building DenseNet169"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def build_network(trainable: bool, retrain_last: bool):\n",
    "    \"\"\"Pre-processes the data for the model\n",
    "        - trainable boolean to indicate if the network would be fully trainable\n",
    "        - retrain_last boolean to indicate if the last layer would be trainable\n",
    "        Returns: densenet_model\n",
    "        - densenet_model is a Keras DenseNet169 model\n",
    "    \"\"\"\n",
    "    densenet_model = keras.applications.DenseNet169(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=None,\n",
    "        input_shape=input_shape_densenet,\n",
    "        pooling=None\n",
    "    )\n",
    "\n",
    "    densenet_model.trainable = True\n",
    "\n",
    "    if not trainable:\n",
    "        for layer in densenet_model.layers:\n",
    "            if retrain_last and 'conv5' in layer.name:\n",
    "                layer.trainable = True\n",
    "            else:\n",
    "                layer.trainable = False\n",
    "\n",
    "    return densenet_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add new layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def add_extra_layers(densenet_model, layer_size: int, dropout: bool, number_of_layers: int):\n",
    "    \"\"\"Add extra layers to a Keras model for transfer learning.\n",
    "        - densenet_model is a pre-trained Keras model with input (224, 224, 3)\n",
    "        - layer_size is an int, the size of the first Dense layer\n",
    "        - dropout is a bool, indicating if a Dropout layer will be added\n",
    "          between Dense layers\n",
    "        Returns: model\n",
    "        - model a Keras model with the layer added\n",
    "    \"\"\"\n",
    "    initializer = keras.initializers.he_normal(seed=32)\n",
    "    inputs = keras.Input(shape=input_shape_densenet)\n",
    "\n",
    "    layer = densenet_model(inputs)\n",
    "    layer = keras.layers.Flatten()(layer)\n",
    "\n",
    "    layer = keras.layers.BatchNormalization()(layer)\n",
    "\n",
    "    for n in range(1, number_of_layers + 1):\n",
    "        layer = keras.layers.Dense(units=layer_size / n,\n",
    "                                   activation='relu',\n",
    "                                   kernel_initializer=initializer\n",
    "                                   )(layer)\n",
    "        if dropout:\n",
    "            layer = keras.layers.Dropout(0.5)(layer)\n",
    "\n",
    "        layer = keras.layers.BatchNormalization()(layer)\n",
    "\n",
    "    layer = keras.layers.Dense(units=7,\n",
    "                               activation='softmax',\n",
    "                               kernel_initializer=initializer\n",
    "                               )(layer)\n",
    "\n",
    "    model = keras.models.Model(inputs, outputs=layer)\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validate results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def build_network_with_params(params: Dict[str, Any]):\n",
    "    network = build_network(params['fully_trainable'], params['retrain_last'])\n",
    "    network = add_extra_layers(network, params['first_layer_size'], params['dropout'], params['number_of_layers'])\n",
    "    network.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=keras.optimizers.Adam(),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    return network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def train_with_k_fold_cross_validation(n_folds: int, params: Dict[str, Any]):\n",
    "    \"\"\"Create and train a DenseNet model n_folds times with a different training/validation partition data.\n",
    "        - n_folds the number of times the model will be trained\n",
    "        - params map string -> value with the configuration of the network, the possible values are:\n",
    "            - first_layer_size is an int, the size of the first Dense layer\n",
    "            - fully_trainable boolean to indicate if the network would be fully trainable\n",
    "            - retrain_last boolean to indicate if the last layer would be trainable\n",
    "            - dropout is a bool, indicating if a Dropout layer will be added\n",
    "              between Dense layers\n",
    "            - number_of_layers is the number of extra layers Dense appended to the network\n",
    "        Returns: histories\n",
    "        - histories a list of size n_folds with the detailed training history of each attempt\n",
    "    \"\"\"\n",
    "    histories = []\n",
    "    for fold in range(n_folds):\n",
    "        network = build_network_with_params(params)\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(x_full_p, y_full_p, test_size=0.2, random_state=fold * 5)\n",
    "        history = network.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), verbose=2)\n",
    "        del network\n",
    "        histories.append(history)\n",
    "\n",
    "    return histories"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "def train_with_simple_holdout_validation(X_train, X_val, y_train, y_val, params: Dict[str, Any]):\n",
    "    \"\"\"Create and train a DenseNet model with the given data.\n",
    "        - params map string -> value with the configuration of the network, the possible values are:\n",
    "            - first_layer_size is an int, the size of the first Dense layer\n",
    "            - fully_trainable boolean to indicate if the network would be fully trainable\n",
    "            - retrain_last boolean to indicate if the last layer would be trainable\n",
    "            - dropout is a bool, indicating if a Dropout layer will be added\n",
    "              between Dense layers\n",
    "            - number_of_layers is the number of extra layers Dense appended to the network\n",
    "        Returns: model\n",
    "        - model a Keras model of th modified DenseNet169\n",
    "    \"\"\"\n",
    "    network = build_network_with_params(params)\n",
    "\n",
    "    history = network.fit(X_train, y_train, epochs=3, validation_data=(X_val, y_val), verbose=2)\n",
    "\n",
    "    network.save('diagrams.h5')\n",
    "    return network, history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Refinement"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "folds = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Helper functions to plot the results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "def get_history_mean(k_history, prop: str):\n",
    "    mean_prop = [h.history[prop] for h in k_history]\n",
    "    mean = np.mean(mean_prop, axis=0)\n",
    "    return mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def build_plot(data, name):\n",
    "    return {'data': data, 'name': name}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def plot_comparison(plots, legends, file_name, nrows, ncols):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    index = 1\n",
    "    for p in plots:\n",
    "        plt.subplot(nrows, ncols, index)\n",
    "        for value in p[\"data\"]:\n",
    "            plt.plot(value)\n",
    "            l = len(value) - 1\n",
    "            plt.text(l, value[l], \"{:.1f}%\".format(value[l] * 100))\n",
    "        plt.legend(legends, loc='lower right')\n",
    "        plt.title(f'Model {p[\"name\"]}')\n",
    "        plt.ylabel(p[\"name\"])\n",
    "        plt.xlabel('epoch')\n",
    "        index += 1\n",
    "\n",
    "    plt.savefig(file_name)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def plot_model_comparison(history, legends, file_name):\n",
    "    metrics = ['val_accuracy', 'val_loss']\n",
    "\n",
    "    plots = [build_plot(map(get_history_mean, history, [metric] * len(history)), metric) for metric in metrics]\n",
    "\n",
    "    plot_comparison(plots, legends, file_name, 1, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Number of extra layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extra_layers_test():\n",
    "    history = []\n",
    "    base_params = {\n",
    "        'first_layer_size': 128,\n",
    "        'fully_trainable': False,\n",
    "        'retrain_last': True,\n",
    "        'dropout': True,\n",
    "    }\n",
    "    n_layers = [0, 1, 2]\n",
    "\n",
    "    for n_layer in n_layers:\n",
    "        params = base_params.update(number_of_layers=n_layer)\n",
    "        h = np.array(train_with_k_fold_cross_validation(folds, params))\n",
    "        history.append(h)\n",
    "    plot_model_comparison(history, n_layers, 'extra_layers.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extra_layers_test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Size of the first layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def first_layer_size_test():\n",
    "    history = []\n",
    "    base_params = {\n",
    "        'fully_trainable': False,\n",
    "        'retrain_last': True,\n",
    "        'dropout': True,\n",
    "        'number_of_layers': 1,\n",
    "    }\n",
    "    first_layer_size = [512, 256, 128, 64]\n",
    "\n",
    "    for layer_size in first_layer_size:\n",
    "        params = base_params.update(first_layer_size=layer_size)\n",
    "        h = np.array(train_with_k_fold_cross_validation(folds, params))\n",
    "        history.append(h)\n",
    "    plot_model_comparison(history, first_layer_size, 'first_layer_size.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "first_layer_size_test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dropout"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dropout_test():\n",
    "    history = []\n",
    "    base_params = {\n",
    "        'first_layer_size': 128,\n",
    "        'fully_trainable': False,\n",
    "        'retrain_last': True,\n",
    "        'number_of_layers': 1,\n",
    "    }\n",
    "    dropout = [True, False]\n",
    "\n",
    "    for option in dropout:\n",
    "        params = base_params.update(dropout=option)\n",
    "        h = np.array(train_with_k_fold_cross_validation(folds, params))\n",
    "        history.append(h)\n",
    "    plot_model_comparison(history, ['Dropout', 'Without'], 'dropout.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dropout_test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Retrain last layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def retrain_last_layer_test():\n",
    "    history = []\n",
    "    base_params = {\n",
    "        'first_layer_size': 128,\n",
    "        'fully_trainable': False,\n",
    "        'dropout': True,\n",
    "        'number_of_layers': 1,\n",
    "    }\n",
    "    retrain_last = [True, False]\n",
    "\n",
    "    for option in retrain_last:\n",
    "        params = base_params.update(retrain_last=option)\n",
    "        h = np.array(train_with_k_fold_cross_validation(folds, params))\n",
    "        history.append(h)\n",
    "    plot_model_comparison(history, ['Retrained', 'Frozen'], 'retrain_last_layer.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "retrain_last_layer_test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validating failed cases and measure model performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def validate_failed(model, X, y, show_image: bool):\n",
    "    print('\\nValidation process:')\n",
    "    prob = model.predict(X, verbose=1)\n",
    "    predictions = prob.argmax(axis=-1)\n",
    "    expected_y = y.argmax(axis=-1)\n",
    "    fails = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] != expected_y[i]:\n",
    "            fails += 1\n",
    "            if show_image:\n",
    "                hash_value = hashlib.sha1(X[i]).hexdigest()[:15]\n",
    "                name = preprocessed_to_name[hash_value]\n",
    "                original = cv2.imread(f'{dataset_folder}/{name}', cv2.IMREAD_ANYCOLOR)\n",
    "\n",
    "                print(\n",
    "                    f'\\r{name} Expected {expected_y[i]} ({prob[i][expected_y[i]]}) but got {predictions[i]} ({prob[i][predictions[i]]})',\n",
    "                    flush=True, end=' ' * 50)\n",
    "\n",
    "                cv2.imshow('Preprocessed', X[i])\n",
    "                cv2.imshow('Original', original)\n",
    "                cv2.waitKey(0)\n",
    "    print(f'Failed: {fails}')\n",
    "\n",
    "    return classification_report(expected_y, predictions, digits=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Final transfer learning model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def generate_final_model(seed: int, show_image: bool):\n",
    "    final_params = {\n",
    "        'first_layer_size': 128,\n",
    "        'fully_trainable': False,\n",
    "        'retrain_last': True,\n",
    "        'dropout': True,\n",
    "        'number_of_layers': 1,\n",
    "    }\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(x_full_p, y_full_p, test_size=0.2, random_state=seed)\n",
    "\n",
    "    model, history = train_with_simple_holdout_validation(X_train, X_val, y_train, y_val, final_params)\n",
    "    report = validate_failed(model, X_val, y_val, show_image)\n",
    "\n",
    "    return model, history, report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " densenet169 (Functional)    (None, 7, 7, 1664)        12642880  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 81536)             0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 81536)            326144    \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               10436736  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,407,175\n",
      "Trainable params: 16,514,567\n",
      "Non-trainable params: 6,892,608\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "139/139 - 86s - loss: 0.3502 - accuracy: 0.8848 - val_loss: 0.1330 - val_accuracy: 0.9613 - 86s/epoch - 622ms/step\n",
      "Epoch 2/3\n",
      "139/139 - 64s - loss: 0.1127 - accuracy: 0.9683 - val_loss: 0.0954 - val_accuracy: 0.9739 - 64s/epoch - 463ms/step\n",
      "Epoch 3/3\n",
      "139/139 - 64s - loss: 0.0685 - accuracy: 0.9800 - val_loss: 0.0882 - val_accuracy: 0.9784 - 64s/epoch - 460ms/step\n",
      "\n",
      "Validation process:\n",
      "35/35 [==============================] - 16s 382ms/step\n",
      "965a700825c7efb.jpg Expected 2 (0.2931957244873047) but got 5 (0.6587546467781067)                                                  "
     ]
    }
   ],
   "source": [
    "transfer_learning_model, transfer_learning_history, report = generate_final_model(random.randint(1, 1000), True)\n",
    "print('\\nClassification report:')\n",
    "print(report)\n",
    "# transfer_learning_model = keras.models.load_model('diagrams.h5')\n",
    "\n",
    "plot_model_comparison([[transfer_learning_history]], ['Transfer learning'], 'transfer_learning_model.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-tuning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fine_tuning(model, seed):\n",
    "    model.trainable = True\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.Adam(1e-5),\n",
    "                  metrics=['accuracy'])\n",
    "    X_train, X_val, y_train, y_val = train_test_split(x_full_p, y_full_p, test_size=0.2, random_state=seed)\n",
    "    model.summary()\n",
    "    history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "    return model, history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fine_tuned_model, fine_tuned_history = fine_tuning(transfer_learning_model, random.randint(1, 1000))\n",
    "plot_model_comparison([fine_tuned_history, transfer_learning_history], ['Fine-tuning', 'Without'], 'fine_tuning.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fine_tuned_model.save('tuned.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing new cases"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model('diagrams.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_and_predict_img(name: str, model):\n",
    "    original = cv2.imread('test/' + name, cv2.IMREAD_ANYCOLOR)\n",
    "    original = cv2.cvtColor(original, cv2.COLOR_RGB2BGR)\n",
    "    img = keras.utils.load_img(f'test/{name}', target_size=input_shape_densenet[:2])\n",
    "    img = keras.utils.img_to_array(img)\n",
    "    x = np.expand_dims(img, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(original)\n",
    "    title = plt.title(f'Original {name}')\n",
    "    plt.setp(title, color='r')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x[0])\n",
    "    title = plt.title(f'Preprocessed {name}')\n",
    "    plt.setp(title, color='r')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    prop = model.predict(x)\n",
    "    prediction = prop.argmax(axis=-1)\n",
    "    print(f\"Prediction: {prediction[0]} -> {class_map[prediction[0]]}\")\n",
    "\n",
    "    return prop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_and_predict_img('pollo.jpg', loaded_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}